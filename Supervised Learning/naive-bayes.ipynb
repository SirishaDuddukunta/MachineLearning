{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a7d39e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.00351,
     "end_time": "2024-12-07T06:38:51.267194",
     "exception": false,
     "start_time": "2024-12-07T06:38:51.263684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding Naive Bayes: A Beginner’s Journey\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. What is Naive Bayes?**\n",
    "\n",
    "**Definition**:  \n",
    "Naive Bayes is a family of simple yet powerful probabilistic algorithms based on Bayes’ Theorem. It assumes that features are **independent** of each other given the target class (this is the \"naive\" part).\n",
    "\n",
    "**Analogy**:  \n",
    "Imagine you're a teacher trying to predict if a student will pass or fail an exam. You base your decision on two independent factors:  \n",
    "1. How often they attend classes.  \n",
    "2. How much time they spend studying.\n",
    "\n",
    "Even though these factors might not be truly independent (students who study more might also attend classes regularly), Naive Bayes assumes they are, making the computation simpler.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Bayes' Theorem**  \n",
    "The foundation of Naive Bayes is **Bayes’ Theorem**, which states:  \n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]\n",
    "\n",
    "- \\(P(A|B)\\): Probability of \\(A\\) happening given \\(B\\) (Posterior Probability).  \n",
    "- \\(P(B|A)\\): Probability of \\(B\\) happening given \\(A\\).  \n",
    "- \\(P(A)\\): Probability of \\(A\\) (Prior Probability).  \n",
    "- \\(P(B)\\): Probability of \\(B\\).\n",
    "\n",
    "**Example in Real Life**:  \n",
    "You want to determine the likelihood that an email is spam (\\(A\\)) given that it contains the word \"discount\" (\\(B\\)).\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Types of Naive Bayes Algorithms**  \n",
    "\n",
    "1. **Gaussian Naive Bayes**: Assumes continuous data follows a normal distribution.  \n",
    "   - Example: Predicting a person’s height given their age.  \n",
    "2. **Multinomial Naive Bayes**: Works with count-based data.  \n",
    "   - Example: Text classification (e.g., spam detection).  \n",
    "3. **Bernoulli Naive Bayes**: Works with binary/Boolean data.  \n",
    "   - Example: Predicting whether a person will buy a product based on yes/no survey answers.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Naive Bayes Links to Other Algorithms**\n",
    "\n",
    "- **Simplicity**: Naive Bayes is often a baseline for classification tasks, especially in text-based problems.\n",
    "- **Comparison**: Unlike logistic regression, which optimizes probabilities iteratively, Naive Bayes relies on direct probabilistic calculations.\n",
    "- **Combination**: Can be integrated into ensemble methods (e.g., combining Naive Bayes with decision trees).\n",
    "\n",
    "---\n",
    "\n",
    "### **Exercises to Practice**  \n",
    "\n",
    "1. **Simple Classification**:  \n",
    "   Classify whether a review is positive or negative using a small dataset.\n",
    "\n",
    "2. **Real-World Application**:  \n",
    "   Use the **20 Newsgroups Dataset** from Scikit-learn to classify articles into categories.\n",
    "\n",
    "3. **Advanced Problem**:  \n",
    "   Implement a Gaussian Naive Bayes classifier for predicting house prices based on features like square footage and number of bedrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b44b10",
   "metadata": {
    "papermill": {
     "duration": 0.002573,
     "end_time": "2024-12-07T06:38:51.272975",
     "exception": false,
     "start_time": "2024-12-07T06:38:51.270402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here are the steps for the Naive Bayes algorithm:\r\n",
    "\r\n",
    "### **Steps in Naive Bayes Algorithm:**\r\n",
    "\r\n",
    "1. **Calculate Prior Probabilities:**\r\n",
    "   - Compute the frequency of each class in the dataset.\r\n",
    "   - Formula: \r\n",
    "     \\[\r\n",
    "     P(\\text{Class}) = \\frac{\\text{Number of instances of class}}{\\text{Total number of instances in the dataset}}\r\n",
    "     \\]\r\n",
    "\r\n",
    "2. **Calculate Likelihood (Feature Probabilities):**\r\n",
    "   - For each feature, calculate the probability of that feature given each class.\r\n",
    "   - Formula:\r\n",
    "     \\[\r\n",
    "     P(\\text{Feature}|\\text{Class}) = \\frac{\\text{Number of instances of class where feature occurs}}{\\text{Total number of instances of the class}}\r\n",
    "     \\]\r\n",
    "\r\n",
    "3. **Apply Bayes' Theorem to Calculate Posterior Probabilities:**\r\n",
    "   - Use Bayes’ Theorem to calculate the probability of each class given the features in the data.\r\n",
    "   - Formula:\r\n",
    "     \\[\r\n",
    "     P(\\text{Class}|\\text{Features}) = \\frac{P(\\text{Features}|\\text{Class}) \\cdot P(\\text{Class})}{P(\\text{Features})}\r\n",
    "     \\]\r\n",
    "   - \\( P(\\text{Features}) \\) is constant for all classes and can be ignored during prediction.\r\n",
    "\r\n",
    "4. **Make Predictions:**\r\n",
    "   - For a new data point, compute the posterior probability for each class using Bayes' Theorem.\r\n",
    "   - The class with the highest posterior probability is the predicted class.\r\n",
    "\r\n",
    "5. **Choose the Class with the Maximum Posterior Probability:**\r\n",
    "   - The class with the highest probability is assigned to the new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828759e",
   "metadata": {
    "papermill": {
     "duration": 0.002531,
     "end_time": "2024-12-07T06:38:51.278373",
     "exception": false,
     "start_time": "2024-12-07T06:38:51.275842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "whether a message is spam or not using Multinomial Naive Bayes.\n",
    "\n",
    "Step 1: Dataset\n",
    "\n",
    "We’ll use a simplified dataset with two features:\n",
    "\n",
    "Words in the message\n",
    "Labels (Spam/Not Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5870f1f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:38:51.286343Z",
     "iopub.status.busy": "2024-12-07T06:38:51.285401Z",
     "iopub.status.idle": "2024-12-07T06:38:52.992928Z",
     "shell.execute_reply": "2024-12-07T06:38:52.991616Z"
    },
    "papermill": {
     "duration": 1.714248,
     "end_time": "2024-12-07T06:38:52.995436",
     "exception": false,
     "start_time": "2024-12-07T06:38:51.281188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample dataset\n",
    "messages = [\n",
    "    \"Free money now\", \n",
    "    \"Urgent offer just for you\", \n",
    "    \"Meeting schedule tomorrow\", \n",
    "    \"Call me when you can\", \n",
    "    \"Congratulations! You won a lottery\", \n",
    "    \"Please find the attached report\"\n",
    "]\n",
    "labels = [1, 1, 0, 0, 1, 0]  # 1 = Spam, 0 = Not Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84298e5c",
   "metadata": {
    "papermill": {
     "duration": 0.002701,
     "end_time": "2024-12-07T06:38:53.001222",
     "exception": false,
     "start_time": "2024-12-07T06:38:52.998521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Step 2: Preprocess Data\n",
    "\n",
    "Convert the text into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe1b203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:38:53.008871Z",
     "iopub.status.busy": "2024-12-07T06:38:53.008362Z",
     "iopub.status.idle": "2024-12-07T06:38:53.031293Z",
     "shell.execute_reply": "2024-12-07T06:38:53.029924Z"
    },
    "papermill": {
     "duration": 0.02966,
     "end_time": "2024-12-07T06:38:53.033795",
     "exception": false,
     "start_time": "2024-12-07T06:38:53.004135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert text to numerical data (Bag-of-Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(messages)\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e7536c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:38:53.041542Z",
     "iopub.status.busy": "2024-12-07T06:38:53.041050Z",
     "iopub.status.idle": "2024-12-07T06:38:53.057932Z",
     "shell.execute_reply": "2024-12-07T06:38:53.056647Z"
    },
    "papermill": {
     "duration": 0.023945,
     "end_time": "2024-12-07T06:38:53.060759",
     "exception": false,
     "start_time": "2024-12-07T06:38:53.036814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Train the Model\n",
    "# Use MultinomialNB for text classification.\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab39f207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:38:53.069417Z",
     "iopub.status.busy": "2024-12-07T06:38:53.068906Z",
     "iopub.status.idle": "2024-12-07T06:38:53.079365Z",
     "shell.execute_reply": "2024-12-07T06:38:53.078046Z"
    },
    "papermill": {
     "duration": 0.018273,
     "end_time": "2024-12-07T06:38:53.082738",
     "exception": false,
     "start_time": "2024-12-07T06:38:53.064465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make Predictions\n",
    "# Test the model’s performance.\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e382de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:38:53.091722Z",
     "iopub.status.busy": "2024-12-07T06:38:53.091345Z",
     "iopub.status.idle": "2024-12-07T06:38:53.100016Z",
     "shell.execute_reply": "2024-12-07T06:38:53.098380Z"
    },
    "papermill": {
     "duration": 0.016037,
     "end_time": "2024-12-07T06:38:53.102696",
     "exception": false,
     "start_time": "2024-12-07T06:38:53.086659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Spam\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Real-World Scenario\n",
    "# You receive the message: \"Win a free iPhone today!\". Predict if it’s spam.\n",
    "# Predict for a new message\n",
    "new_message = [\"Win a free iPhone today!\"]\n",
    "new_message_vectorized = vectorizer.transform(new_message)\n",
    "prediction = model.predict(new_message_vectorized)\n",
    "print(\"Spam\" if prediction[0] == 1 else \"Not Spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa74494",
   "metadata": {
    "papermill": {
     "duration": 0.003185,
     "end_time": "2024-12-07T06:38:53.109399",
     "exception": false,
     "start_time": "2024-12-07T06:38:53.106214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Naive Bayes Methods**  \r\n",
    "\r\n",
    "Naive Bayes is a family of algorithms tailored for specific types of data distributions. Here are the key types of Naive Bayes methods:  \r\n",
    "\r\n",
    "#### **1. Gaussian Naive Bayes**  \r\n",
    "- **Use case**: Continuous data assumed to follow a normal (Gaussian) distribution.  \r\n",
    "- **Real-world example**: Predicting the likelihood of a student passing based on their grades and hours studied (continuous variables).  \r\n",
    "\r\n",
    "#### **2. Multinomial Naive Bayes**  \r\n",
    "- **Use case**: Count-based or frequency-based data.  \r\n",
    "- **Real-world example**: Text classification, spam detection, or sentiment analysis.  \r\n",
    "\r\n",
    "#### **3. Bernoulli Naive Bayes**  \r\n",
    "- **Use case**: Binary/Boolean data (features are either 1 or 0).  \r\n",
    "- **Real-world example**: Document classification where features indicate the presence or absence of specific words.  \r\n",
    "\r\n",
    "#### **4. Complement Naive Bayes**  \r\n",
    "- **Use case**: Addresses issues with imbalanced datasets, primarily for text classification.  \r\n",
    "- **Real-world example**: Handling datasets where one class (e.g., \"Not Spam\") significantly outweighs another class (e.g., \"Spam\").  \r\n",
    "\r\n",
    "#### **5. Categorical Naive Bayes**  \r\n",
    "- **Use case**: Categorical features with discrete categories.  \r\n",
    "- **Real-world example**: Predicting a person’s job role based on discrete attributes like education level and marital status.  \r\n",
    "\r\n",
    "#### **6. Outlier-Aware Naive Bayes**  \r\n",
    "- **Use case**: Modified to handle noisy or outlier data.  \r\n",
    "- **Real-world example**: Medical diagnosis where rare cases (outliers) may skew results.  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Naive Bayes Interview Questions and Answers**  \r\n",
    "\r\n",
    "#### **Beginner-Level Questions**  \r\n",
    "\r\n",
    "1. **What is Naive Bayes? Explain its basic assumption.**  \r\n",
    "   - **Answer**: Naive Bayes is a probabilistic algorithm based on Bayes’ Theorem. It assumes that all features are independent given the target class (the \"naive\" assumption).  \r\n",
    "\r\n",
    "2. **What are the types of Naive Bayes algorithms?**  \r\n",
    "   - **Answer**: Gaussian, Multinomial, Bernoulli, Complement, and Categorical Naive Bayes.  \r\n",
    "\r\n",
    "3. **What are some use cases of Naive Bayes?**  \r\n",
    "   - **Answer**:  \r\n",
    "     - Spam detection.  \r\n",
    "     - Sentiment analysis.  \r\n",
    "     - Medical diagnosis.  \r\n",
    "     - Document classification.  \r\n",
    "\r\n",
    "4. **What are the pros and cons of Naive Bayes?**  \r\n",
    "   - **Answer**:  \r\n",
    "     - **Pros**: Simple, fast, works well with small datasets, handles high-dimensional data efficiently.  \r\n",
    "     - **Cons**: Assumes feature independence, struggles with correlated features or zero probabilities.  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### **Intermediate-Level Questions**  \r\n",
    "\r\n",
    "5. **How does Naive Bayes handle continuous data?**  \r\n",
    "   - **Answer**: Continuous data is handled by Gaussian Naive Bayes, which assumes that the data follows a normal distribution.  \r\n",
    "\r\n",
    "6. **What is Laplace smoothing, and why is it used in Naive Bayes?**  \r\n",
    "   - **Answer**: Laplace smoothing adds a small constant to all probabilities to avoid zero probabilities when a particular feature value is missing in the training data.  \r\n",
    "\r\n",
    "7. **How does Multinomial Naive Bayes differ from Bernoulli Naive Bayes?**  \r\n",
    "   - **Answer**:  \r\n",
    "     - Multinomial Naive Bayes is used for count-based data (e.g., term frequencies in text).  \r\n",
    "     - Bernoulli Naive Bayes works with binary data, representing the presence or absence of features.  \r\n",
    "\r\n",
    "8. **What are some limitations of Naive Bayes?**  \r\n",
    "   - **Answer**:  \r\n",
    "     - Assumes feature independence.  \r\n",
    "     - Sensitive to irrelevant features.  \r\n",
    "     - Performs poorly when data distributions deviate from assumptions.  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### **Advanced-Level Questions**  \r\n",
    "\r\n",
    "9. **Can Naive Bayes be used for regression tasks? Why or why not?**  \r\n",
    "   - **Answer**: Naive Bayes is inherently a classification algorithm. For regression tasks, other probabilistic models like Bayesian Linear Regression are more suitable.  \r\n",
    "\r\n",
    "10. **What happens when features are highly correlated in Naive Bayes?**  \r\n",
    "    - **Answer**: Naive Bayes assumes independence among features. When features are highly correlated, the algorithm overestimates probabilities, leading to suboptimal results.  \r\n",
    "\r\n",
    "11. **How do you handle imbalanced datasets in Naive Bayes?**  \r\n",
    "    - **Answer**: Complement Naive Bayes is designed to handle imbalanced datasets. Alternatively, techniques like resampling or adjusting class weights can be used.  \r\n",
    "\r\n",
    "12. **Explain how Naive Bayes can be used in ensemble learning.**  \r\n",
    "    - **Answer**: Naive Bayes can be used as a base learner in ensemble methods like stacking or bagging. Its probabilistic outputs can complement other models in a diverse ensemble.  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Real-World Scenarios**  \r\n",
    "\r\n",
    "- **Spam Detection**: Use Multinomial Naive Bayes to classify emails.  \r\n",
    "- **Text Classification**: Classify news articles into predefined categories.  \r\n",
    "- **Medical Diagnosis**: Use Gaussian Naive Bayes to predict diseases based on patient attributes (e.g., age, blood pressure).  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Tips for Naive Bayes Interview Preparation**  \r\n",
    "\r\n",
    "1. **Understand Bayes' Theorem deeply**: Know how it’s derived and applied.  \r\n",
    "2. **Practice coding**: Implement Naive Bayes algorithms from scratch and using libraries like Scikit-learn.  \r\n",
    "3. **Explain feature independence**: Be ready to discuss its implications and limitations.  \r\n",
    "4. **Work with datasets**: Experiment with real-world datasets like spam detection or sentiment analysis.  \r\n",
    "5. **Compare algorithms**: Be able to articulate how Naive Bayes compares with other classifiers like Logistic Regression or SVM.  e Logistic Regression or SVM.  \r\n",
    "\r\n",
    "Would you like detailed coding examples or additional practice problems?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.143918,
   "end_time": "2024-12-07T06:38:53.635193",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T06:38:48.491275",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
